# Module 3: Analyzer - Claude Code Instructions

**Version:** 2.0 (PoC Aligned)  
**Updated:** November 26, 2025  
**Status:** Ready for Implementation  
**Priority:** Phase 2 - Core Module (Build Third in Phase 2)

---

## PoC Scope Summary

| Feature | Status | Notes |
|---------|--------|-------|
| Skill matching via vectors | ✅ In Scope | Semantic similarity search |
| Experience matching | ✅ In Scope | Find relevant experiences |
| Gap identification | ✅ In Scope | Missing requirements |
| Compatibility scoring | ✅ In Scope | Overall match percentage |
| Strategy generation via LLM | ✅ In Scope | Application positioning |
| Multi-job comparison | ❌ Deferred | Single job analysis |
| Historical analysis | ❌ Deferred | Not needed for PoC |
| Market insights | ❌ Deferred | No external data |

---

## Context & Objective

Build the **Analyzer Module** for Scout - compares user profile against job requirements, calculates compatibility, identifies gaps, and generates application strategy.

### Why This Module Exists

The Analyzer is the intelligence layer that:
- Matches user skills to job requirements semantically
- Identifies which requirements are met and which are gaps
- Calculates an overall compatibility score
- Generates positioning strategy for the application

This bridges Collector (user data) and Rinser (job data) to inform Creator.

### Dependencies

This module **requires**:
- **M1 Collector**: For user profile and skill search
- **M2 Rinser**: ProcessedJob as input
- **S4 Vector Store Service**: For semantic matching
- **S1 LLM Service**: For strategy generation

---

## Technical Requirements

### File Structure

```
scout/
├── app/
│   ├── models/
│   │   └── analysis.py          # Analysis data models
│   ├── core/
│   │   └── analyzer.py          # Analyzer module
│   └── prompts/
│       └── analysis.py          # Analysis prompts
└── tests/
    └── unit/
        └── core/
            └── test_analyzer.py
```

---

## Data Models

Create `app/models/analysis.py`:

```python
"""
Analysis Data Models

Models for job-profile matching and strategy generation.
"""

from pydantic import BaseModel, Field, computed_field
from typing import List, Optional, Dict, Any
from datetime import datetime
from enum import Enum


class MatchLevel(str, Enum):
    """Overall compatibility level."""
    EXCELLENT = "excellent"  # 85-100%
    STRONG = "strong"        # 70-84%
    MODERATE = "moderate"    # 50-69%
    WEAK = "weak"            # 30-49%
    POOR = "poor"            # 0-29%


class SkillMatch(BaseModel):
    """
    Match between a job requirement and user skills.
    
    Example:
        requirement_text: "5+ years Python experience"
        matched_skills: ["Python (expert, 6 years)"]
        score: 0.92
        is_met: True
    """
    requirement_text: str
    requirement_priority: str  # "must_have", "nice_to_have"
    matched_skills: List[str]  # Skill names that match
    score: float = Field(ge=0, le=1)  # Similarity score
    is_met: bool = False
    gap_reason: Optional[str] = None  # Why not met


class ExperienceMatch(BaseModel):
    """
    Match between job responsibilities and user experiences.
    
    Example:
        responsibility_text: "Design REST APIs"
        matched_experience: "Senior Developer at TechCorp"
        relevance_score: 0.85
        matching_keywords: ["API", "REST", "Python"]
    """
    responsibility_text: str
    matched_experience: Optional[str] = None  # Experience title/company
    relevance_score: float = Field(ge=0, le=1)
    matching_keywords: List[str] = Field(default_factory=list)


class QualificationGap(BaseModel):
    """
    An identified gap in qualifications.
    
    Example:
        requirement: "AWS certification required"
        importance: "must_have"
        gap_type: "certification"
        suggested_action: "Highlight cloud experience, mention willingness to certify"
    """
    requirement: str
    importance: str  # "must_have", "nice_to_have"
    gap_type: str  # "skill", "experience", "education", "certification"
    current_level: Optional[str] = None  # What user has
    suggested_action: str = ""


class ApplicationStrategy(BaseModel):
    """
    Strategy for the application.
    
    Generated by LLM based on analysis.
    """
    positioning: str  # How to position the application
    key_strengths: List[str]  # Top 3-5 strengths to highlight
    address_gaps: List[str]  # How to address gaps
    tone: str  # Recommended tone
    keywords_to_use: List[str]  # ATS-friendly keywords
    opening_hook: Optional[str] = None  # Suggested cover letter opening


class CompatibilityScore(BaseModel):
    """
    Detailed compatibility breakdown.
    """
    # Overall
    overall: float = Field(ge=0, le=100)  # Percentage
    level: MatchLevel = MatchLevel.MODERATE
    
    # Breakdown
    technical_skills: float = Field(ge=0, le=100)
    experience_relevance: float = Field(ge=0, le=100)
    requirements_met: float = Field(ge=0, le=100)  # % of must-haves met
    
    # Counts
    must_haves_met: int = 0
    must_haves_total: int = 0
    nice_to_haves_met: int = 0
    nice_to_haves_total: int = 0


class AnalysisResult(BaseModel):
    """
    Complete analysis of job-profile match.
    
    This is the output of the Analyzer module.
    """
    # Identification
    job_id: str
    job_title: str
    company_name: str
    
    # Scores
    compatibility: CompatibilityScore
    
    # Detailed matches
    skill_matches: List[SkillMatch] = Field(default_factory=list)
    experience_matches: List[ExperienceMatch] = Field(default_factory=list)
    
    # Gaps
    gaps: List[QualificationGap] = Field(default_factory=list)
    
    # Strategy
    strategy: Optional[ApplicationStrategy] = None
    
    # Metadata
    analyzed_at: datetime = Field(default_factory=datetime.now)
    
    @computed_field
    @property
    def is_good_match(self) -> bool:
        """Check if this is a good match (70%+)."""
        return self.compatibility.overall >= 70
    
    @computed_field
    @property
    def critical_gaps(self) -> List[QualificationGap]:
        """Get must-have gaps only."""
        return [g for g in self.gaps if g.importance == "must_have"]
```

---

## Analysis Prompts

Create `app/prompts/analysis.py`:

```python
"""
LLM Prompts for Analysis

Prompts used by the Analyzer module for strategy generation.
"""

STRATEGY_SYSTEM_PROMPT = """You are a career advisor helping craft job application strategies.
You analyze job requirements against candidate qualifications to provide actionable advice.
Be specific, practical, and focus on what makes the candidate stand out."""

STRATEGY_GENERATION_PROMPT = """Generate an application strategy based on this analysis.

Job Title: {job_title}
Company: {company_name}

Compatibility Score: {overall_score}%
Must-have requirements met: {must_haves_met}/{must_haves_total}

Key Skill Matches:
{skill_matches_text}

Experience Matches:
{experience_matches_text}

Gaps Identified:
{gaps_text}

Generate a JSON strategy:
{{
    "positioning": "2-3 sentence positioning statement for this application",
    "key_strengths": ["strength1", "strength2", "strength3"],
    "address_gaps": ["how to address gap1", "how to address gap2"],
    "tone": "professional|enthusiastic|technical|creative",
    "keywords_to_use": ["keyword1", "keyword2", "keyword3"],
    "opening_hook": "Compelling opening sentence for cover letter"
}}

Guidelines:
- Position around strengths, not gaps
- Be specific about how to address gaps (not just "mention willingness to learn")
- Include keywords from the job posting for ATS
- Match tone to company culture if apparent"""
```

---

## Module Implementation

Create `app/core/analyzer.py`:

```python
"""
Analyzer Module

Compares user profile to job requirements and generates strategy.

Usage:
    analyzer = Analyzer(collector, vector_store, llm_service)
    
    result = await analyzer.analyze(processed_job)
    print(f"Compatibility: {result.compatibility.overall}%")
    print(f"Strategy: {result.strategy.positioning}")
"""

import logging
from typing import List, Optional, Tuple

from app.models.job import ProcessedJob, Requirement, RequirementPriority
from app.models.profile import UserProfile, Skill, Experience
from app.models.analysis import (
    AnalysisResult, CompatibilityScore, MatchLevel,
    SkillMatch, ExperienceMatch, QualificationGap, ApplicationStrategy
)
from app.models.vectors import CollectionName
from app.core.collector import Collector
from app.services.vector_store import VectorStoreService
from app.services.llm import LLMService
from app.prompts.analysis import STRATEGY_SYSTEM_PROMPT, STRATEGY_GENERATION_PROMPT
from app.utils.exceptions import ScoutError

logger = logging.getLogger(__name__)


class AnalyzerError(ScoutError):
    """Error in Analyzer operations."""
    pass


class Analyzer:
    """
    Analyzer Module - matches profile to job and generates strategy.
    
    Responsibilities:
    - Match skills to requirements semantically
    - Match experiences to responsibilities
    - Identify qualification gaps
    - Calculate compatibility score
    - Generate application strategy via LLM
    
    Attributes:
        collector: Collector for profile access
        vector_store: Vector Store for semantic search
        llm: LLM Service for strategy generation
        
    Example:
        >>> analyzer = Analyzer(collector, vector_store, llm)
        >>> result = await analyzer.analyze(job)
        >>> print(f"Match: {result.compatibility.level.value}")
        "Match: strong"
        >>> print(result.strategy.positioning)
        "Position yourself as an experienced Python developer..."
    """
    
    # Thresholds for matching
    SKILL_MATCH_THRESHOLD = 0.5  # Minimum similarity for skill match
    EXPERIENCE_MATCH_THRESHOLD = 0.4  # Minimum for experience match
    
    # Weights for compatibility calculation
    WEIGHT_MUST_HAVE = 0.5
    WEIGHT_NICE_TO_HAVE = 0.2
    WEIGHT_EXPERIENCE = 0.3
    
    def __init__(
        self,
        collector: Collector,
        vector_store: VectorStoreService,
        llm_service: LLMService
    ):
        """
        Initialize Analyzer.
        
        Args:
            collector: Collector with loaded profile
            vector_store: Vector Store for semantic search
            llm_service: LLM Service for strategy generation
        """
        self._collector = collector
        self._vector_store = vector_store
        self._llm = llm_service
    
    # =========================================================================
    # SKILL MATCHING
    # =========================================================================
    
    async def _match_skills(
        self,
        requirements: List[Requirement]
    ) -> Tuple[List[SkillMatch], int, int]:
        """
        Match user skills against job requirements.
        
        Args:
            requirements: Job requirements to match
            
        Returns:
            Tuple of (skill_matches, must_haves_met, nice_to_haves_met)
        """
        matches = []
        must_haves_met = 0
        nice_to_haves_met = 0
        
        for req in requirements:
            # Search for matching skills
            skills = await self._collector.find_relevant_skills(
                requirement_text=req.text,
                top_k=3,
                threshold=self.SKILL_MATCH_THRESHOLD
            )
            
            # Build match result
            matched_skill_names = [
                f"{s.name} ({s.level.value}, {s.years or '?'} years)"
                for s in skills
            ]
            
            is_met = len(skills) > 0
            score = skills[0].years / 10 if skills and skills[0].years else 0.5 if skills else 0.0
            score = min(score, 1.0)  # Cap at 1.0
            
            gap_reason = None
            if not is_met:
                gap_reason = "No matching skills found"
            elif req.years_required:
                # Check if years requirement is met
                max_years = max((s.years or 0) for s in skills)
                if max_years < req.years_required:
                    gap_reason = f"Have {max_years} years, need {req.years_required}"
                    is_met = False
            
            match = SkillMatch(
                requirement_text=req.text,
                requirement_priority=req.priority.value,
                matched_skills=matched_skill_names,
                score=score,
                is_met=is_met,
                gap_reason=gap_reason
            )
            matches.append(match)
            
            # Count met requirements
            if is_met:
                if req.priority == RequirementPriority.MUST_HAVE:
                    must_haves_met += 1
                else:
                    nice_to_haves_met += 1
        
        return matches, must_haves_met, nice_to_haves_met
    
    # =========================================================================
    # EXPERIENCE MATCHING
    # =========================================================================
    
    async def _match_experiences(
        self,
        job: ProcessedJob
    ) -> List[ExperienceMatch]:
        """
        Match user experiences against job responsibilities.
        
        Args:
            job: Processed job with responsibilities
            
        Returns:
            List of experience matches
        """
        matches = []
        
        for resp in job.responsibilities:
            # Search for relevant experiences
            experiences = await self._collector.find_relevant_experiences(
                requirement_text=resp.text,
                top_k=1,
                threshold=self.EXPERIENCE_MATCH_THRESHOLD
            )
            
            if experiences:
                exp = experiences[0]
                # Extract matching keywords
                keywords = self._extract_matching_keywords(resp.text, exp)
                
                match = ExperienceMatch(
                    responsibility_text=resp.text,
                    matched_experience=f"{exp.title} at {exp.company}",
                    relevance_score=0.7,  # Could be improved with actual scores
                    matching_keywords=keywords
                )
            else:
                match = ExperienceMatch(
                    responsibility_text=resp.text,
                    matched_experience=None,
                    relevance_score=0.0,
                    matching_keywords=[]
                )
            
            matches.append(match)
        
        return matches
    
    def _extract_matching_keywords(
        self,
        responsibility_text: str,
        experience: Experience
    ) -> List[str]:
        """Extract keywords that appear in both texts."""
        resp_words = set(responsibility_text.lower().split())
        exp_text = experience.to_searchable_text().lower()
        
        # Also check technologies
        keywords = []
        for tech in experience.technologies:
            if tech.lower() in responsibility_text.lower():
                keywords.append(tech)
        
        # Common meaningful words
        for word in resp_words:
            if len(word) > 3 and word in exp_text:
                keywords.append(word)
        
        return list(set(keywords))[:5]  # Limit to 5
    
    # =========================================================================
    # GAP ANALYSIS
    # =========================================================================
    
    def _identify_gaps(
        self,
        skill_matches: List[SkillMatch],
        job: ProcessedJob
    ) -> List[QualificationGap]:
        """
        Identify qualification gaps.
        
        Args:
            skill_matches: Results from skill matching
            job: Processed job
            
        Returns:
            List of gaps
        """
        gaps = []
        
        for match in skill_matches:
            if not match.is_met:
                gap = QualificationGap(
                    requirement=match.requirement_text,
                    importance=match.requirement_priority,
                    gap_type=self._determine_gap_type(match.requirement_text),
                    current_level=", ".join(match.matched_skills) if match.matched_skills else None,
                    suggested_action=self._suggest_gap_action(match)
                )
                gaps.append(gap)
        
        return gaps
    
    def _determine_gap_type(self, requirement_text: str) -> str:
        """Determine the type of gap based on requirement text."""
        text_lower = requirement_text.lower()
        
        if any(word in text_lower for word in ["degree", "bachelor", "master", "phd"]):
            return "education"
        elif any(word in text_lower for word in ["certified", "certification"]):
            return "certification"
        elif any(word in text_lower for word in ["years", "experience"]):
            return "experience"
        else:
            return "skill"
    
    def _suggest_gap_action(self, match: SkillMatch) -> str:
        """Suggest how to address a gap."""
        if match.matched_skills:
            return f"Emphasize related skills: {', '.join(match.matched_skills[:2])}"
        elif "years" in match.requirement_text.lower():
            return "Highlight project complexity and impact over raw years"
        else:
            return "Mention willingness to learn and any adjacent experience"
    
    # =========================================================================
    # COMPATIBILITY SCORING
    # =========================================================================
    
    def _calculate_compatibility(
        self,
        skill_matches: List[SkillMatch],
        experience_matches: List[ExperienceMatch],
        must_haves_met: int,
        nice_to_haves_met: int,
        job: ProcessedJob
    ) -> CompatibilityScore:
        """
        Calculate overall compatibility score.
        
        Args:
            skill_matches: Skill match results
            experience_matches: Experience match results
            must_haves_met: Count of must-haves met
            nice_to_haves_met: Count of nice-to-haves met
            job: Processed job
            
        Returns:
            CompatibilityScore
        """
        must_haves = job.get_must_have_requirements()
        nice_to_haves = [r for r in job.requirements if r.priority != RequirementPriority.MUST_HAVE]
        
        # Calculate component scores
        must_have_score = (must_haves_met / len(must_haves) * 100) if must_haves else 100
        nice_to_have_score = (nice_to_haves_met / len(nice_to_haves) * 100) if nice_to_haves else 100
        
        # Experience score
        matched_exp = [m for m in experience_matches if m.matched_experience]
        experience_score = (len(matched_exp) / len(experience_matches) * 100) if experience_matches else 50
        
        # Technical skills average
        tech_scores = [m.score * 100 for m in skill_matches]
        technical_score = sum(tech_scores) / len(tech_scores) if tech_scores else 50
        
        # Weighted overall score
        overall = (
            must_have_score * self.WEIGHT_MUST_HAVE +
            nice_to_have_score * self.WEIGHT_NICE_TO_HAVE +
            experience_score * self.WEIGHT_EXPERIENCE
        )
        
        # Determine level
        if overall >= 85:
            level = MatchLevel.EXCELLENT
        elif overall >= 70:
            level = MatchLevel.STRONG
        elif overall >= 50:
            level = MatchLevel.MODERATE
        elif overall >= 30:
            level = MatchLevel.WEAK
        else:
            level = MatchLevel.POOR
        
        return CompatibilityScore(
            overall=round(overall, 1),
            level=level,
            technical_skills=round(technical_score, 1),
            experience_relevance=round(experience_score, 1),
            requirements_met=round(must_have_score, 1),
            must_haves_met=must_haves_met,
            must_haves_total=len(must_haves),
            nice_to_haves_met=nice_to_haves_met,
            nice_to_haves_total=len(nice_to_haves)
        )
    
    # =========================================================================
    # STRATEGY GENERATION
    # =========================================================================
    
    async def _generate_strategy(
        self,
        job: ProcessedJob,
        compatibility: CompatibilityScore,
        skill_matches: List[SkillMatch],
        experience_matches: List[ExperienceMatch],
        gaps: List[QualificationGap]
    ) -> ApplicationStrategy:
        """
        Generate application strategy via LLM.
        
        Args:
            job: Processed job
            compatibility: Compatibility score
            skill_matches: Skill matches
            experience_matches: Experience matches
            gaps: Identified gaps
            
        Returns:
            ApplicationStrategy
        """
        # Format matches for prompt
        skill_text = "\n".join([
            f"- {m.requirement_text}: {'✓ Met' if m.is_met else '✗ Gap'} "
            f"(matched: {', '.join(m.matched_skills) or 'none'})"
            for m in skill_matches[:5]
        ])
        
        exp_text = "\n".join([
            f"- {m.responsibility_text}: {m.matched_experience or 'No match'}"
            for m in experience_matches[:5]
        ])
        
        gaps_text = "\n".join([
            f"- [{g.importance}] {g.requirement}: {g.gap_type}"
            for g in gaps[:5]
        ]) or "No significant gaps"
        
        prompt = STRATEGY_GENERATION_PROMPT.format(
            job_title=job.title,
            company_name=job.company.name,
            overall_score=compatibility.overall,
            must_haves_met=compatibility.must_haves_met,
            must_haves_total=compatibility.must_haves_total,
            skill_matches_text=skill_text,
            experience_matches_text=exp_text,
            gaps_text=gaps_text
        )
        
        try:
            result = await self._llm.generate_json(
                prompt=prompt,
                system=STRATEGY_SYSTEM_PROMPT,
                module="analyzer",
                purpose="generate_strategy"
            )
            
            return ApplicationStrategy(
                positioning=result.get("positioning", ""),
                key_strengths=result.get("key_strengths", []),
                address_gaps=result.get("address_gaps", []),
                tone=result.get("tone", "professional"),
                keywords_to_use=result.get("keywords_to_use", []),
                opening_hook=result.get("opening_hook")
            )
            
        except Exception as e:
            logger.warning(f"Strategy generation failed: {e}, using fallback")
            return ApplicationStrategy(
                positioning="Highlight relevant experience and transferable skills.",
                key_strengths=["Technical proficiency", "Relevant experience"],
                address_gaps=["Mention willingness to learn new technologies"],
                tone="professional",
                keywords_to_use=[]
            )
    
    # =========================================================================
    # MAIN ANALYSIS
    # =========================================================================
    
    async def analyze(
        self,
        job: ProcessedJob,
        generate_strategy: bool = True
    ) -> AnalysisResult:
        """
        Analyze job-profile compatibility.
        
        Main entry point for the Analyzer module.
        
        Args:
            job: Processed job from Rinser
            generate_strategy: Whether to generate LLM strategy
            
        Returns:
            AnalysisResult with compatibility and strategy
            
        Example:
            >>> result = await analyzer.analyze(job)
            >>> print(f"Compatibility: {result.compatibility.overall}%")
            >>> print(f"Level: {result.compatibility.level.value}")
            >>> if result.is_good_match:
            ...     print("Good match! Proceed with application.")
        """
        logger.info(f"Analyzing job: {job.title} at {job.company.name}")
        
        # Step 1: Match skills to requirements
        skill_matches, must_haves_met, nice_to_haves_met = await self._match_skills(
            job.requirements
        )
        logger.debug(f"Skill matches: {must_haves_met} must-haves, {nice_to_haves_met} nice-to-haves")
        
        # Step 2: Match experiences to responsibilities
        experience_matches = await self._match_experiences(job)
        matched_exp_count = len([m for m in experience_matches if m.matched_experience])
        logger.debug(f"Experience matches: {matched_exp_count}/{len(experience_matches)}")
        
        # Step 3: Identify gaps
        gaps = self._identify_gaps(skill_matches, job)
        logger.debug(f"Gaps identified: {len(gaps)}")
        
        # Step 4: Calculate compatibility score
        compatibility = self._calculate_compatibility(
            skill_matches=skill_matches,
            experience_matches=experience_matches,
            must_haves_met=must_haves_met,
            nice_to_haves_met=nice_to_haves_met,
            job=job
        )
        logger.info(f"Compatibility: {compatibility.overall}% ({compatibility.level.value})")
        
        # Step 5: Generate strategy (optional)
        strategy = None
        if generate_strategy:
            strategy = await self._generate_strategy(
                job=job,
                compatibility=compatibility,
                skill_matches=skill_matches,
                experience_matches=experience_matches,
                gaps=gaps
            )
        
        return AnalysisResult(
            job_id=job.id,
            job_title=job.title,
            company_name=job.company.name,
            compatibility=compatibility,
            skill_matches=skill_matches,
            experience_matches=experience_matches,
            gaps=gaps,
            strategy=strategy
        )
```

---

## Test Implementation

Create `tests/unit/core/test_analyzer.py`:

```python
"""
Unit tests for Analyzer Module.

Run with: pytest tests/unit/core/test_analyzer.py -v
"""

import pytest
from unittest.mock import Mock, AsyncMock

from app.core.analyzer import Analyzer, AnalyzerError
from app.models.analysis import (
    AnalysisResult, CompatibilityScore, MatchLevel,
    SkillMatch, ApplicationStrategy
)
from app.models.job import (
    ProcessedJob, Requirement, Responsibility, CompanyInfo,
    RequirementPriority, RequirementCategory
)
from app.models.profile import Skill, Experience, SkillLevel, SkillCategory
from datetime import date


# =============================================================================
# FIXTURES
# =============================================================================

@pytest.fixture
def sample_job():
    """Create sample processed job."""
    return ProcessedJob(
        id="test-job",
        title="Senior Python Developer",
        company=CompanyInfo(name="TechCorp"),
        requirements=[
            Requirement(
                text="5+ years Python experience",
                priority=RequirementPriority.MUST_HAVE,
                category=RequirementCategory.TECHNICAL,
                years_required=5
            ),
            Requirement(
                text="FastAPI knowledge",
                priority=RequirementPriority.MUST_HAVE,
                category=RequirementCategory.TECHNICAL
            ),
            Requirement(
                text="AWS experience preferred",
                priority=RequirementPriority.NICE_TO_HAVE,
                category=RequirementCategory.TECHNICAL
            )
        ],
        responsibilities=[
            Responsibility(text="Design REST APIs", category=RequirementCategory.TECHNICAL),
            Responsibility(text="Mentor junior developers", category=RequirementCategory.SOFT_SKILL)
        ],
        raw_text="Job posting text"
    )


@pytest.fixture
def mock_collector():
    """Create mock Collector."""
    collector = Mock()
    
    # Mock skill search
    collector.find_relevant_skills = AsyncMock(return_value=[
        Skill(
            name="Python",
            level=SkillLevel.EXPERT,
            years=6,
            category=SkillCategory.PROGRAMMING
        )
    ])
    
    # Mock experience search
    collector.find_relevant_experiences = AsyncMock(return_value=[
        Experience(
            company="PrevCorp",
            title="Software Engineer",
            start_date=date(2020, 1, 1),
            description="Built APIs",
            technologies=["Python", "FastAPI"]
        )
    ])
    
    return collector


@pytest.fixture
def mock_vector_store():
    """Create mock Vector Store."""
    return AsyncMock()


@pytest.fixture
def mock_llm_service():
    """Create mock LLM Service."""
    llm = AsyncMock()
    llm.generate_json.return_value = {
        "positioning": "Position as experienced Python developer",
        "key_strengths": ["Python expertise", "API design"],
        "address_gaps": ["Highlight AWS learning path"],
        "tone": "professional",
        "keywords_to_use": ["Python", "FastAPI", "REST"],
        "opening_hook": "As a senior Python developer..."
    }
    return llm


@pytest.fixture
def analyzer(mock_collector, mock_vector_store, mock_llm_service):
    """Create Analyzer for testing."""
    return Analyzer(mock_collector, mock_vector_store, mock_llm_service)


# =============================================================================
# SKILL MATCHING TESTS
# =============================================================================

class TestSkillMatching:
    """Tests for skill matching."""
    
    @pytest.mark.asyncio
    async def test_match_skills_found(self, analyzer, sample_job):
        """Should match skills when found."""
        matches, must_met, nice_met = await analyzer._match_skills(
            sample_job.requirements
        )
        
        assert len(matches) == 3
        assert must_met >= 1  # At least Python match
    
    @pytest.mark.asyncio
    async def test_match_skills_not_found(self, analyzer, mock_collector, sample_job):
        """Should handle no matches."""
        mock_collector.find_relevant_skills.return_value = []
        
        matches, must_met, nice_met = await analyzer._match_skills(
            sample_job.requirements
        )
        
        assert all(not m.is_met for m in matches)
        assert must_met == 0


# =============================================================================
# EXPERIENCE MATCHING TESTS
# =============================================================================

class TestExperienceMatching:
    """Tests for experience matching."""
    
    @pytest.mark.asyncio
    async def test_match_experiences(self, analyzer, sample_job):
        """Should match experiences to responsibilities."""
        matches = await analyzer._match_experiences(sample_job)
        
        assert len(matches) == 2
        assert matches[0].matched_experience is not None
    
    @pytest.mark.asyncio
    async def test_match_experiences_none(self, analyzer, mock_collector, sample_job):
        """Should handle no experience matches."""
        mock_collector.find_relevant_experiences.return_value = []
        
        matches = await analyzer._match_experiences(sample_job)
        
        assert all(m.matched_experience is None for m in matches)


# =============================================================================
# GAP IDENTIFICATION TESTS
# =============================================================================

class TestGapIdentification:
    """Tests for gap identification."""
    
    def test_identify_gaps(self, analyzer, sample_job):
        """Should identify gaps from unmet requirements."""
        skill_matches = [
            SkillMatch(
                requirement_text="AWS certification",
                requirement_priority="must_have",
                matched_skills=[],
                score=0,
                is_met=False
            )
        ]
        
        gaps = analyzer._identify_gaps(skill_matches, sample_job)
        
        assert len(gaps) == 1
        assert gaps[0].requirement == "AWS certification"
    
    def test_no_gaps_when_all_met(self, analyzer, sample_job):
        """Should return empty when all met."""
        skill_matches = [
            SkillMatch(
                requirement_text="Python",
                requirement_priority="must_have",
                matched_skills=["Python"],
                score=0.9,
                is_met=True
            )
        ]
        
        gaps = analyzer._identify_gaps(skill_matches, sample_job)
        
        assert len(gaps) == 0


# =============================================================================
# COMPATIBILITY SCORING TESTS
# =============================================================================

class TestCompatibilityScoring:
    """Tests for compatibility scoring."""
    
    def test_calculate_compatibility_high(self, analyzer, sample_job):
        """Should calculate high score when well matched."""
        skill_matches = [
            SkillMatch(requirement_text="Python", requirement_priority="must_have",
                      matched_skills=["Python"], score=0.9, is_met=True),
            SkillMatch(requirement_text="FastAPI", requirement_priority="must_have",
                      matched_skills=["FastAPI"], score=0.8, is_met=True),
        ]
        experience_matches = []
        
        score = analyzer._calculate_compatibility(
            skill_matches=skill_matches,
            experience_matches=experience_matches,
            must_haves_met=2,
            nice_to_haves_met=0,
            job=sample_job
        )
        
        assert score.overall >= 70
        assert score.level in [MatchLevel.EXCELLENT, MatchLevel.STRONG]
    
    def test_calculate_compatibility_low(self, analyzer, sample_job):
        """Should calculate low score when poorly matched."""
        skill_matches = [
            SkillMatch(requirement_text="Python", requirement_priority="must_have",
                      matched_skills=[], score=0, is_met=False),
        ]
        experience_matches = []
        
        score = analyzer._calculate_compatibility(
            skill_matches=skill_matches,
            experience_matches=experience_matches,
            must_haves_met=0,
            nice_to_haves_met=0,
            job=sample_job
        )
        
        assert score.overall < 50
        assert score.level in [MatchLevel.WEAK, MatchLevel.POOR]


# =============================================================================
# STRATEGY GENERATION TESTS
# =============================================================================

class TestStrategyGeneration:
    """Tests for strategy generation."""
    
    @pytest.mark.asyncio
    async def test_generate_strategy(self, analyzer, sample_job, mock_llm_service):
        """Should generate strategy via LLM."""
        compatibility = CompatibilityScore(
            overall=75, level=MatchLevel.STRONG,
            technical_skills=80, experience_relevance=70, requirements_met=75,
            must_haves_met=2, must_haves_total=2
        )
        
        strategy = await analyzer._generate_strategy(
            job=sample_job,
            compatibility=compatibility,
            skill_matches=[],
            experience_matches=[],
            gaps=[]
        )
        
        assert strategy.positioning != ""
        assert len(strategy.key_strengths) > 0
        mock_llm_service.generate_json.assert_called_once()


# =============================================================================
# FULL ANALYSIS TESTS
# =============================================================================

class TestAnalyze:
    """Tests for full analysis flow."""
    
    @pytest.mark.asyncio
    async def test_analyze_success(self, analyzer, sample_job):
        """Should complete full analysis."""
        result = await analyzer.analyze(sample_job)
        
        assert isinstance(result, AnalysisResult)
        assert result.job_id == sample_job.id
        assert result.job_title == sample_job.title
        assert result.compatibility is not None
        assert result.strategy is not None
    
    @pytest.mark.asyncio
    async def test_analyze_without_strategy(self, analyzer, sample_job, mock_llm_service):
        """Should skip strategy generation when disabled."""
        result = await analyzer.analyze(sample_job, generate_strategy=False)
        
        assert result.strategy is None
        mock_llm_service.generate_json.assert_not_called()
    
    @pytest.mark.asyncio
    async def test_is_good_match_property(self, analyzer, sample_job):
        """Should calculate is_good_match correctly."""
        result = await analyzer.analyze(sample_job)
        
        expected = result.compatibility.overall >= 70
        assert result.is_good_match == expected
```

---

## Implementation Steps

### Step M3.1: Data Models
```bash
# Create app/models/analysis.py
# Verify:
python -c "from app.models.analysis import AnalysisResult, CompatibilityScore; print('OK')"
```

### Step M3.2: Analysis Prompts
```bash
# Create app/prompts/analysis.py
# Verify:
python -c "from app.prompts.analysis import STRATEGY_GENERATION_PROMPT; print('OK')"
```

### Step M3.3: Module Implementation
```bash
# Create app/core/analyzer.py
# Verify:
python -c "from app.core.analyzer import Analyzer; print('OK')"
```

### Step M3.4: Unit Tests
```bash
# Create tests/unit/core/test_analyzer.py
# Verify:
pytest tests/unit/core/test_analyzer.py -v
```

### Step M3.5: Integration Test
```bash
# Verify end-to-end (uses all services):
python -c "
import asyncio
from app.services.llm import get_llm_service
from app.services.vector_store import get_vector_store
from app.core.collector import create_collector
from app.core.rinser import Rinser
from app.core.analyzer import Analyzer

JOB_TEXT = '''... (paste job text) ...'''

async def test():
    llm = await get_llm_service()
    vs = await get_vector_store()
    collector = await create_collector(vs)
    rinser = Rinser(llm, vs)
    analyzer = Analyzer(collector, vs, llm)
    
    job = await rinser.process_job(JOB_TEXT)
    result = await analyzer.analyze(job)
    
    print(f'Job: {result.job_title}')
    print(f'Compatibility: {result.compatibility.overall}%')
    print(f'Level: {result.compatibility.level.value}')
    print(f'Strategy: {result.strategy.positioning}')

asyncio.run(test())
"
```

---

## Success Criteria

| Metric | Target | Verification |
|--------|--------|--------------|
| Skill matching | Semantic relevance | Test with known profile/job |
| Gap identification | All unmet found | Compare to manual analysis |
| Scoring accuracy | Reflects match quality | Test edge cases |
| Strategy generation | Actionable advice | Review LLM output |
| Test coverage | >90% | `pytest --cov=app/core/analyzer` |

---

*This specification is aligned with Scout PoC Scope Document v1.0*
